{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "indt.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cLChoQZ6YYS",
        "outputId": "586063d0-7e10-4d40-d17b-eef90358269e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBphiTTU5BDg"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, MaxPool1D, Flatten, Dropout, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pvZdV8kAFL_"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXmu6D2qFkHX"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import string, re\n",
        "from collections import Counter\n",
        "import wordcloud\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoAwNlRKSRK7"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a6z9b-FQFGg"
      },
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-RNbOPE5UvP",
        "outputId": "69e3588d-49cb-4a64-cf8a-e4efe0f1e228"
      },
      "source": [
        "from DAL import DAL\n",
        "from preprocessing import *\n",
        "from classifiers import Classsifier"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8pcfL0f5YLl"
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zbQ8qVO5ZSJ"
      },
      "source": [
        "dal = DAL(\"/content/drive/MyDrive/Colab Notebooks/data/data.csv\")\n",
        "data = dal.get()\n",
        "l = [sample[0] for sample in data]\n",
        "x = [sample[1] for sample in data]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jty7p5hiF-LN"
      },
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(l)\n",
        "target = le.transform(l)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0Alsg-hFdO8",
        "outputId": "84ae1c84-e7e1-4e73-a389-be006a47afa5"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(21070, 50, input_length=427))\n",
        "model.add(Conv1D(32, 8, activation=\"relu\"))\n",
        "model.add(MaxPool1D(4))\n",
        "model.add(Conv1D(16, 8, activation=\"relu\"))\n",
        "model.add(MaxPool1D(4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation=\"relu\"))\n",
        "model.add(Dense(5,  activation=\"softmax\"))   \n",
        "model.summary()\n",
        "model.compile('adam', metrics=['accuracy'],loss='categorical_crossentropy')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 427, 50)           1053500   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 420, 32)           12832     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 105, 32)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 98, 16)            4112      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 24, 16)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                3850      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 55        \n",
            "=================================================================\n",
            "Total params: 1,074,349\n",
            "Trainable params: 1,074,349\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRmaQFoiE3mv"
      },
      "source": [
        "classassifier = Classsifier(\"C1d\", [Tokenize(), Normalize(), RemoveStopWords(), Steamer(),  BreakSequence(), Dry(), Join(),  Words2index()], model)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65SIfR47F1aO",
        "outputId": "5cf0468c-ffdb-4711-b3d0-4770b875b45a"
      },
      "source": [
        "classassifier.train(x, target)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------\n",
            "Training: C1d\n",
            "\n",
            "{'min': 47, 'max': 2186, 'mean': 214.17393258426966, 'std': 123.7672946727131, 'recomended': 461}\n",
            "Total data for training: 1557, For testing: 668 \n",
            "\n",
            "Epoch 1/5\n",
            "49/49 [==============================] - 20s 73ms/step - loss: 1.5827 - accuracy: 0.2417\n",
            "Epoch 2/5\n",
            "49/49 [==============================] - 4s 73ms/step - loss: 1.2658 - accuracy: 0.4872\n",
            "Epoch 3/5\n",
            "49/49 [==============================] - 4s 73ms/step - loss: 0.3620 - accuracy: 0.8948\n",
            "Epoch 4/5\n",
            "49/49 [==============================] - 4s 72ms/step - loss: 0.0513 - accuracy: 0.9943\n",
            "Epoch 5/5\n",
            "49/49 [==============================] - 4s 73ms/step - loss: 0.0082 - accuracy: 0.9999\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.89      0.92       164\n",
            "           1       0.95      0.89      0.92       113\n",
            "           2       0.93      0.94      0.93       113\n",
            "           3       1.00      0.98      0.99       146\n",
            "           4       0.82      0.94      0.87       132\n",
            "\n",
            "    accuracy                           0.93       668\n",
            "   macro avg       0.93      0.93      0.93       668\n",
            "weighted avg       0.93      0.93      0.93       668\n",
            "\n",
            "Confusion matrix: \n",
            "\n",
            "[[146   0   6   0  12]\n",
            " [  0 101   1   0  11]\n",
            " [  2   1 106   0   4]\n",
            " [  0   1   1 143   1]\n",
            " [  5   3   0   0 124]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}